{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YATBAZ_aerial_cactus_identification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HknyYtbz/cng-562/blob/master/YATBAZ_aerial_cactus_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4GbGJyhbpDr",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs4Z6K4NDgCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNyYkFmhRCDz",
        "colab_type": "text"
      },
      "source": [
        "Please upload your Kaggle API JSON named as kaggle.json to download the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGlH-08iYSHc",
        "colab_type": "code",
        "outputId": "9ef26373-304f-470f-a558-e268fb997d03",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "from google.colab import files\n",
        "#Kaggle api key upload\n",
        "files.upload()\n",
        "#Essential downloads for the project, especially the kaggle dataset download\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json \n",
        "!kaggle competitions download -c aerial-cactus-identification\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ca92095-de65-46ab-ab73-826485ea1d3a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0ca92095-de65-46ab-ab73-826485ea1d3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/667k [00:00<?, ?B/s]\n",
            "100% 667k/667k [00:00<00:00, 45.7MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/160k [00:00<?, ?B/s]\n",
            "100% 160k/160k [00:00<00:00, 50.0MB/s]\n",
            "Downloading test.zip to /content\n",
            "100% 4.20M/4.20M [00:00<00:00, 27.1MB/s]\n",
            "\n",
            "Downloading train.zip to /content\n",
            " 88% 17.0M/19.2M [00:00<00:00, 30.5MB/s]\n",
            "100% 19.2M/19.2M [00:00<00:00, 55.2MB/s]\n",
            "kaggle.json  sample_data  sample_submission.csv  test.zip  train.csv  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_bacOrJo637",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/train.zip\", 'r')\n",
        "!mkdir cactus\n",
        "zip_ref.extractall(\"/content/cactus\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QZJwpW_AFb2",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBjQCONGAho1",
        "colab_type": "text"
      },
      "source": [
        "##Image  to Tensor Conversion & Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5SHKXb4vemJ",
        "colab_type": "code",
        "outputId": "ad4e590e-a26a-46b6-e265-15ec2711eaee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "device = None\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "    device = \"cpu\"\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    device = \"cuda\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykqewgwGTEV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "data.head()\n",
        "pth = \"/content/cactus/train/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdkDD0RdXS8m",
        "colab_type": "code",
        "outputId": "895d1ea2-d03b-430d-dc8b-6861eeec44e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "data.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['0004be2cfeaba1c0361d39e2b000257b.jpg', 1],\n",
              "       ['000c8a36845c0208e833c79c1bffedd1.jpg', 1],\n",
              "       ['000d1e9a533f62e55c289303b072733d.jpg', 1],\n",
              "       ...,\n",
              "       ['fff059ecc91b30be5745e8b81111dc7b.jpg', 1],\n",
              "       ['fff43acb3b7a23edcc4ae937be2b7522.jpg', 0],\n",
              "       ['fffd9e9b990eba07c836745d8aef1a3a.jpg', 1]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySq-_inauXTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms \n",
        "\n",
        "def train_tf(x):\n",
        "    im_aug = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    x = im_aug(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv6AYtusuhZH",
        "colab_type": "code",
        "outputId": "48c508b8-2a86-4f8e-cb1b-e14420013199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "\n",
        "train_img = []\n",
        "train_label = []\n",
        "for i in data.values:\n",
        "    img = cv2.imread(pth+i[0])\n",
        "    tf_img = Image.fromarray(img.astype('uint8')).convert('RGB')\n",
        "    tf_img1 = train_tf(tf_img)\n",
        "    train_img.append((tf_img1, i[1]))\n",
        "\n",
        "import random\n",
        "test_data = random.sample(train_img, int(0.2 * len(train_img)))\n",
        "train_data = list(set(train_img).difference(set(test_data)))\n",
        "val_data = random.sample(train_img, int(0.1 * len(train_img)))\n",
        "train_data = list(set(train_img).difference(set(val_data)))\n",
        "\n",
        "print(\"\")\n",
        "print(len(train_data),len(test_data),len(val_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "15750 3500 1750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMLhbnInPn9y",
        "colab_type": "code",
        "outputId": "9f701487-f602-43c8-caa4-df73796127c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lZf2gCVptSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size) \n",
        "\n",
        "# specify the image classes\n",
        "classes = [\"No Cactus\",'Cactus']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIXLR3WNArKn",
        "colab_type": "text"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HOBpDdmtIKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwr1mLxtuse",
        "colab_type": "code",
        "outputId": "cd4c266b-6c35-4dea-de1c-90d6d3001e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# display 20 images\n",
        "for idx in np.arange(10):\n",
        "    ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.8627451\n",
            "1.0\n",
            "0.7921569\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.99215686\n",
            "0.81960785\n",
            "0.78431374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABPoAAAD7CAYAAADzafoaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEnCh51AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1800x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00gehLQGBNF_",
        "colab_type": "text"
      },
      "source": [
        "#CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKt2uQtKut7e",
        "colab_type": "code",
        "outputId": "3a9b1c48-e496-453b-8293-a2f04e8b4d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layer (sees 360x360x3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        \n",
        "        # convolutional layer (sees 16x16x16 tensor)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        \n",
        "        # convolutional layer (sees 8x8x32 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "       \n",
        "        \n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # linear layer (64 * 12 * 12 -> 4096)\n",
        "        self.fc1 = nn.Linear(32*4*4, 512)\n",
        "        \n",
        "        # linear layer (500 -> 10)\n",
        "        \n",
        "        \n",
        "        self.fc2 = nn.Linear(512,256)\n",
        "        self.fc3 = nn.Linear(256,2)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        #print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        #print(x.shape)\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 32 * 4 * 4)\n",
        "        #print(x.shape)\n",
        "        # add dropout layer\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        # add dropout layer\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.dropout(F.relu(self.fc2(x)))  \n",
        "        x = self.dropout(self.fc3(x)) \n",
        "        return x\n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.25)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr4qnASnBPyo",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vThGvfHvyFD",
        "colab_type": "code",
        "outputId": "18921bde-2e65-4d13-811f-a7d355801e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "n_epochs = 30\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), \"/content/cactus_model.pt\")\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.581458 \tValidation Loss: 0.547148\n",
            "Validation loss decreased (inf --> 0.547148).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.565927 \tValidation Loss: 0.528009\n",
            "Validation loss decreased (0.547148 --> 0.528009).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.489491 \tValidation Loss: 0.335104\n",
            "Validation loss decreased (0.528009 --> 0.335104).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.342451 \tValidation Loss: 0.208256\n",
            "Validation loss decreased (0.335104 --> 0.208256).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.268228 \tValidation Loss: 0.172823\n",
            "Validation loss decreased (0.208256 --> 0.172823).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.236076 \tValidation Loss: 0.143319\n",
            "Validation loss decreased (0.172823 --> 0.143319).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.217163 \tValidation Loss: 0.139783\n",
            "Validation loss decreased (0.143319 --> 0.139783).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.204470 \tValidation Loss: 0.121122\n",
            "Validation loss decreased (0.139783 --> 0.121122).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.195641 \tValidation Loss: 0.123901\n",
            "Epoch: 10 \tTraining Loss: 0.187993 \tValidation Loss: 0.117424\n",
            "Validation loss decreased (0.121122 --> 0.117424).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.181535 \tValidation Loss: 0.103804\n",
            "Validation loss decreased (0.117424 --> 0.103804).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.174248 \tValidation Loss: 0.103004\n",
            "Validation loss decreased (0.103804 --> 0.103004).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.173150 \tValidation Loss: 0.094302\n",
            "Validation loss decreased (0.103004 --> 0.094302).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.164727 \tValidation Loss: 0.089018\n",
            "Validation loss decreased (0.094302 --> 0.089018).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 0.155578 \tValidation Loss: 0.096241\n",
            "Epoch: 16 \tTraining Loss: 0.154618 \tValidation Loss: 0.083580\n",
            "Validation loss decreased (0.089018 --> 0.083580).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 0.148764 \tValidation Loss: 0.079046\n",
            "Validation loss decreased (0.083580 --> 0.079046).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.146160 \tValidation Loss: 0.070756\n",
            "Validation loss decreased (0.079046 --> 0.070756).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 0.139628 \tValidation Loss: 0.075156\n",
            "Epoch: 20 \tTraining Loss: 0.136533 \tValidation Loss: 0.072714\n",
            "Epoch: 21 \tTraining Loss: 0.134643 \tValidation Loss: 0.060030\n",
            "Validation loss decreased (0.070756 --> 0.060030).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 0.130986 \tValidation Loss: 0.060017\n",
            "Validation loss decreased (0.060030 --> 0.060017).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 0.128212 \tValidation Loss: 0.068272\n",
            "Epoch: 24 \tTraining Loss: 0.126619 \tValidation Loss: 0.054569\n",
            "Validation loss decreased (0.060017 --> 0.054569).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 0.121719 \tValidation Loss: 0.055670\n",
            "Epoch: 26 \tTraining Loss: 0.119487 \tValidation Loss: 0.080746\n",
            "Epoch: 27 \tTraining Loss: 0.125539 \tValidation Loss: 0.058686\n",
            "Epoch: 28 \tTraining Loss: 0.123852 \tValidation Loss: 0.047870\n",
            "Validation loss decreased (0.054569 --> 0.047870).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 0.125119 \tValidation Loss: 0.051783\n",
            "Epoch: 30 \tTraining Loss: 0.113345 \tValidation Loss: 0.043858\n",
            "Validation loss decreased (0.047870 --> 0.043858).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl2Z3KSTBTMB",
        "colab_type": "text"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbrDbMtIzCkC",
        "colab_type": "code",
        "outputId": "9539a876-783c-4fef-c5b4-6dcb15746549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model.load_state_dict(torch.load(\"/content/cactus_model.pt\"))\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(len(classes)))\n",
        "class_total = list(0. for i in range(len(classes)))\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    ct = 0\n",
        "    for i in range(len(list(target.data))   ):\n",
        "        try:\n",
        "            label = target.data[i]\n",
        "            #print(correct)\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "        except IndexError:\n",
        "            ct+=1\n",
        "            continue\n",
        "#print(\"Problematic Count: %d\"%ct)\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.050251\n",
            "\n",
            "Test Accuracy of No Cactus: 95% (842/885)\n",
            "Test Accuracy of Cactus: 99% (2594/2615)\n",
            "\n",
            "Test Accuracy (Overall): 98% (3436/3500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFmcs2Uk3gli",
        "colab_type": "text"
      },
      "source": [
        "#Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGDc8fzL1ppo",
        "colab_type": "text"
      },
      "source": [
        "##DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgaR4M993bND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "model2 =models.densenet121(pretrained=True)\n",
        "#print(model2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzCxO4sE_jB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(\n",
        "        OrderedDict([   ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ])\n",
        "    )\n",
        "model2.classifier = classifier\n",
        "#print(model2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA6MQZRz7dyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model2.classifier.parameters(), lr=0.003)\n",
        "criterion = nn.NLLLoss()\n",
        "#model2.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_24uWARBXTx",
        "colab_type": "text"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmdAvOkD8Q_y",
        "colab_type": "code",
        "outputId": "d5519a87-a423-4b62-a263-2a0a435e48cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "n_epochs = 30\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model2.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model2(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model2.eval()\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model2(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model2.state_dict(), \"/content/cactus_modelDense.pt\")\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.288653 \tValidation Loss: 0.315957\n",
            "Validation loss decreased (inf --> 0.315957).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.212256 \tValidation Loss: 0.420261\n",
            "Epoch: 3 \tTraining Loss: 0.173405 \tValidation Loss: 0.443511\n",
            "Epoch: 4 \tTraining Loss: 0.139085 \tValidation Loss: 0.553977\n",
            "Epoch: 5 \tTraining Loss: 0.106227 \tValidation Loss: 0.577670\n",
            "Epoch: 6 \tTraining Loss: 0.089293 \tValidation Loss: 0.622139\n",
            "Epoch: 7 \tTraining Loss: 0.080199 \tValidation Loss: 1.111834\n",
            "Epoch: 8 \tTraining Loss: 0.076077 \tValidation Loss: 0.645682\n",
            "Epoch: 9 \tTraining Loss: 0.071176 \tValidation Loss: 1.130723\n",
            "Epoch: 10 \tTraining Loss: 0.065080 \tValidation Loss: 1.545496\n",
            "Epoch: 11 \tTraining Loss: 0.051402 \tValidation Loss: 1.374199\n",
            "Epoch: 12 \tTraining Loss: 0.049382 \tValidation Loss: 1.185562\n",
            "Epoch: 13 \tTraining Loss: 0.039709 \tValidation Loss: 1.292913\n",
            "Epoch: 14 \tTraining Loss: 0.031089 \tValidation Loss: 1.094481\n",
            "Epoch: 15 \tTraining Loss: 0.031170 \tValidation Loss: 1.531394\n",
            "Epoch: 16 \tTraining Loss: 0.026571 \tValidation Loss: 2.035389\n",
            "Epoch: 17 \tTraining Loss: 0.023514 \tValidation Loss: 2.104679\n",
            "Epoch: 18 \tTraining Loss: 0.024264 \tValidation Loss: 1.693554\n",
            "Epoch: 19 \tTraining Loss: 0.021693 \tValidation Loss: 1.542183\n",
            "Epoch: 20 \tTraining Loss: 0.018570 \tValidation Loss: 1.535741\n",
            "Epoch: 21 \tTraining Loss: 0.019580 \tValidation Loss: 2.075781\n",
            "Epoch: 22 \tTraining Loss: 0.016547 \tValidation Loss: 2.321978\n",
            "Epoch: 23 \tTraining Loss: 0.024707 \tValidation Loss: 1.258509\n",
            "Epoch: 24 \tTraining Loss: 0.016185 \tValidation Loss: 1.408168\n",
            "Epoch: 25 \tTraining Loss: 0.012851 \tValidation Loss: 1.624460\n",
            "Epoch: 26 \tTraining Loss: 0.014376 \tValidation Loss: 1.848146\n",
            "Epoch: 27 \tTraining Loss: 0.011671 \tValidation Loss: 2.088983\n",
            "Epoch: 28 \tTraining Loss: 0.015302 \tValidation Loss: 2.727674\n",
            "Epoch: 29 \tTraining Loss: 0.013497 \tValidation Loss: 1.403227\n",
            "Epoch: 30 \tTraining Loss: 0.015215 \tValidation Loss: 2.286650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3_ItI2tBcGi",
        "colab_type": "text"
      },
      "source": [
        "###Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZTMXbPU9Qe8",
        "colab_type": "code",
        "outputId": "c4cefb5c-101c-47b3-b48a-2b6e94876edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model2.load_state_dict(torch.load(\"/content/cactus_modelDense.pt\"))\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(len(classes)))\n",
        "class_total = list(0. for i in range(len(classes)))\n",
        "model2.eval()\n",
        "# iterate over test data\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model2(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    ct = 0\n",
        "    for i in range(len(list(target.data))   ):\n",
        "        try:\n",
        "            label = target.data[i]\n",
        "            #print(correct)\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "        except IndexError:\n",
        "            ct+=1\n",
        "            continue\n",
        "#print(\"Problematic Count: %d\"%ct)\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.322314\n",
            "\n",
            "Test Accuracy of No Cactus: 80% (715/885)\n",
            "Test Accuracy of Cactus: 97% (2544/2615)\n",
            "\n",
            "Test Accuracy (Overall): 93% (3259/3500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LTelWv92U4u",
        "colab_type": "text"
      },
      "source": [
        "##ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVz4oyYd2YMa",
        "colab_type": "code",
        "outputId": "a625fe27-a3fa-4b7f-f6db-cd0f047e3d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3007
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "model3 =models.resnet50(pretrained=True)\n",
        "print(model3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
            "100%|| 102502400/102502400 [00:01<00:00, 81785945.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQierMPi5qz5",
        "colab_type": "code",
        "outputId": "58532552-a047-4cf7-a691-61709a47fbec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3142
        }
      },
      "source": [
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                                 (\"fc\",nn.Linear(2048, 1000)),\n",
        "                                 (\"relu\",nn.ReLU()),\n",
        "                                 (\"dropout\",nn.Dropout(0.2)),\n",
        "                                 (\"a1\",nn.Linear(1000, 512)),\n",
        "                                 (\"relu\",nn.ReLU()),\n",
        "                                 (\"dropout\",nn.Dropout(0.2)),\n",
        "                                 (\"a2\",nn.Linear(512, 256)),\n",
        "                                 (\"relu2\",nn.ReLU()),\n",
        "                                 (\"dropout2\",nn.Dropout(0.2)),\n",
        "                                 (\"a3\",nn.Linear(256, 2)),\n",
        "                                (\"output\", nn.LogSoftmax(dim=1))]))\n",
        "model3.fc = classifier\n",
        "criterion = nn.NLLLoss()\n",
        "# Only train the classifier parameters, feature parameters are frozen\n",
        "optimizer = optim.Adam(model3.fc.parameters(), lr=0.003)\n",
        "\n",
        "model3.to(device);\n",
        "print(model3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout): Dropout(p=0.2)\n",
            "    (a1): Linear(in_features=1000, out_features=512, bias=True)\n",
            "    (a2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (relu2): ReLU()\n",
            "    (dropout2): Dropout(p=0.2)\n",
            "    (a3): Linear(in_features=256, out_features=2, bias=True)\n",
            "    (output): LogSoftmax()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyzR-b-YBf8T",
        "colab_type": "text"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTM1fgTz85jd",
        "colab_type": "code",
        "outputId": "5bdf36c1-d86f-4f42-d976-fa7013adc7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "n_epochs = 30\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model3.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model3(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model3.eval()\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model3(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model3.state_dict(), \"/content/cactus_modelResNet50.pt\")\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.404669 \tValidation Loss: 0.993865\n",
            "Validation loss decreased (inf --> 0.993865).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.325676 \tValidation Loss: 0.585328\n",
            "Validation loss decreased (0.993865 --> 0.585328).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.326939 \tValidation Loss: 0.341785\n",
            "Validation loss decreased (0.585328 --> 0.341785).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.324269 \tValidation Loss: 0.956106\n",
            "Epoch: 5 \tTraining Loss: 0.302684 \tValidation Loss: 0.403404\n",
            "Epoch: 6 \tTraining Loss: 0.307074 \tValidation Loss: 1.547060\n",
            "Epoch: 7 \tTraining Loss: 0.290946 \tValidation Loss: 0.239570\n",
            "Validation loss decreased (0.341785 --> 0.239570).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.307798 \tValidation Loss: 0.507115\n",
            "Epoch: 9 \tTraining Loss: 0.277728 \tValidation Loss: 0.947925\n",
            "Epoch: 10 \tTraining Loss: 0.286134 \tValidation Loss: 2.052384\n",
            "Epoch: 11 \tTraining Loss: 0.295858 \tValidation Loss: 0.258821\n",
            "Epoch: 12 \tTraining Loss: 0.284777 \tValidation Loss: 0.276332\n",
            "Epoch: 13 \tTraining Loss: 0.307537 \tValidation Loss: 0.315572\n",
            "Epoch: 14 \tTraining Loss: 0.283558 \tValidation Loss: 0.298807\n",
            "Epoch: 15 \tTraining Loss: 0.330928 \tValidation Loss: 0.354126\n",
            "Epoch: 16 \tTraining Loss: 0.298541 \tValidation Loss: 0.294563\n",
            "Epoch: 17 \tTraining Loss: 0.289018 \tValidation Loss: 0.296022\n",
            "Epoch: 18 \tTraining Loss: 0.278784 \tValidation Loss: 0.300198\n",
            "Epoch: 19 \tTraining Loss: 0.295108 \tValidation Loss: 0.276218\n",
            "Epoch: 20 \tTraining Loss: 0.268497 \tValidation Loss: 0.285062\n",
            "Epoch: 21 \tTraining Loss: 0.289599 \tValidation Loss: 0.308261\n",
            "Epoch: 22 \tTraining Loss: 0.286735 \tValidation Loss: 0.279743\n",
            "Epoch: 23 \tTraining Loss: 0.267815 \tValidation Loss: 0.314323\n",
            "Epoch: 24 \tTraining Loss: 0.262089 \tValidation Loss: 0.337583\n",
            "Epoch: 25 \tTraining Loss: 0.268218 \tValidation Loss: 0.418526\n",
            "Epoch: 26 \tTraining Loss: 0.261208 \tValidation Loss: 0.354329\n",
            "Epoch: 27 \tTraining Loss: 0.295626 \tValidation Loss: 0.333380\n",
            "Epoch: 28 \tTraining Loss: 0.280207 \tValidation Loss: 0.290468\n",
            "Epoch: 29 \tTraining Loss: 0.268245 \tValidation Loss: 0.268704\n",
            "Epoch: 30 \tTraining Loss: 0.252600 \tValidation Loss: 0.293630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcPqMAHGBhSp",
        "colab_type": "text"
      },
      "source": [
        "###Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4HFNuTt8XNr",
        "colab_type": "code",
        "outputId": "2e021200-dfe8-4238-a6c8-cb723cc1539a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model3.load_state_dict(torch.load(\"/content/cactus_modelResNet50.pt\"))\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(len(classes)))\n",
        "class_total = list(0. for i in range(len(classes)))\n",
        "model3.eval()\n",
        "# iterate over test data\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model3(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    ct = 0\n",
        "    for i in range(len(list(target.data))   ):\n",
        "        try:\n",
        "            label = target.data[i]\n",
        "            #print(correct)\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "        except IndexError:\n",
        "            ct+=1\n",
        "            continue\n",
        "#print(\"Problematic Count: %d\"%ct)\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.257843\n",
            "\n",
            "Test Accuracy of No Cactus: 67% (595/885)\n",
            "Test Accuracy of Cactus: 95% (2507/2615)\n",
            "\n",
            "Test Accuracy (Overall): 88% (3102/3500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7FleYGtBkA2",
        "colab_type": "text"
      },
      "source": [
        "#Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeMy4vdi2tWH",
        "colab_type": "text"
      },
      "source": [
        "In this dataset, we had many images (32x32) labeled as cactus or not cactus . I simply load the data using PyTorch (with their respective label) and generated a train and test sample ( In the process I coverted images to sensors and appied some transformations to make the model more robust). Apart from that no processing done on the data.\n",
        "\n",
        "I used my own CNN network with 3 convolutional layer and 3 fully connected layer. Convolutional layers have 32 3x3 kernels and max pooling layer between them.  For training I have also generated a validation set from the training set to avoid overfitting and saved the model when the validation loss is decreased. The accuracy obtained is  98%.\n",
        "\n",
        "Having tried the model I implemented, I have also tried pretrained DenseNet and ResNet by modifying their fully connected layers and obtained  93% and 88% respectively.\n",
        " \n",
        "As a future work, other pretrained models can be used or different CNN architectures can be applied.\n",
        "\n",
        "All in all, in this dataset, I had a chance to explore CNN and well-known architectures better and learned how to load different type of image datasets."
      ]
    }
  ]
}